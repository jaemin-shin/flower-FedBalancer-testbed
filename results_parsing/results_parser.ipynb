{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_elapsed_time(str_time):\n",
    "    tmp = str_time.split(':')\n",
    "    return float(int(tmp[0]) * 3600 + int(tmp[1]) * 60) + float(tmp[2])\n",
    "\n",
    "def parse_config_log_realexperiment(filename):\n",
    "    f = open(filename)\n",
    "\n",
    "    lines = f.readlines()\n",
    "    round_time = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    for line in lines:\n",
    "        tmp = line.strip().split(' ')\n",
    "        if 'fit_round' in tmp and 'received' in tmp:\n",
    "            round_time.append(parse_elapsed_time(tmp[tmp.index('fit_round')-2]))\n",
    "        elif 'fit' in tmp and 'progress:' in tmp:\n",
    "            test_accuracy.append(float(tmp[tmp.index('progress:')+4][:-2]))\n",
    "    \n",
    "    results = {}\n",
    "    results['round_time'] = round_time\n",
    "    results['test_accuracy'] = test_accuracy\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def measure_time(log_dict, objective, what_to_check):\n",
    "    i = -1\n",
    "    for i, acc in enumerate(log_dict[what_to_check]):\n",
    "        if acc >= objective:\n",
    "            return log_dict['round_time'][i]\n",
    "    return sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_final_acc(log_dict, what_to_check, global_final_time):\n",
    "    for i in range(len(log_dict['round_time'])):\n",
    "        if log_dict['round_time'][i] >= global_final_time:\n",
    "            return log_dict[what_to_check][i-1]\n",
    "    return log_dict[what_to_check][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged Results\n",
      "METHOD          | SPEEDUP     | ACCURACY  \n",
      "FedAvg+1T       | 0.99 ± 0.02 | 0.852 ± 0.020\n",
      "FedAvg+2T       | 0.75 ± 0.30 | 0.833 ± 0.034\n",
      "FedAvg+SPC      | 0.61 ± 0.35 | 0.850 ± 0.013\n",
      "FedAvg+WFA      | 0.92 ± 0.07 | 0.846 ± 0.007\n",
      "Prox+1T         | 1.03 ± 0.23 | 0.860 ± 0.007\n",
      "Prox+2T         | 0.90 ± 0.20 | 0.860 ± 0.012\n",
      "SampleSelection | 1.00 ± 0.13 | 0.846 ± 0.015\n",
      "FedBalancer     | 1.34 ± 0.07 | 0.885 ± 0.017\n"
     ]
    }
   ],
   "source": [
    "global_final_times = [981, 1452, 1110]\n",
    "\n",
    "speedup = np.zeros((3, 8))\n",
    "accuracy = np.zeros((3, 8))\n",
    "\n",
    "for batch_idx in range(1,4,1):\n",
    "    log_path = '../android/log/experiments_batch'+str(batch_idx)+'/'\n",
    "    fedavg_1T = parse_config_log_realexperiment(log_path+'fedavg_final_experiment_ddl_1T_'+str(batch_idx)+'.log')\n",
    "    fedavg_2T = parse_config_log_realexperiment(log_path+'fedavg_final_experiment_ddl_2T_'+str(batch_idx)+'.log')\n",
    "    fedavg_spc = parse_config_log_realexperiment(log_path+'fedavg_final_experiment_ddl_smartpc_'+str(batch_idx)+'.log')\n",
    "    fedavg_wfa = parse_config_log_realexperiment(log_path+'fedavg_final_experiment_ddl_wfa_'+str(batch_idx)+'.log')\n",
    "\n",
    "    fedprox_1T = parse_config_log_realexperiment(log_path+'fedprox_final_experiment_ddl_1T_'+str(batch_idx)+'.log')\n",
    "    fedprox_2T = parse_config_log_realexperiment(log_path+'fedprox_final_experiment_ddl_2T_'+str(batch_idx)+'.log')\n",
    "    fedprox_ss = parse_config_log_realexperiment(log_path+'fedprox_final_experiment_ss_'+str(batch_idx)+'.log')\n",
    "\n",
    "    fedbalancer = parse_config_log_realexperiment(log_path+'fedbalancer_final_experiment_'+str(batch_idx)+'.log')\n",
    "    \n",
    "    global_final_time = global_final_times[batch_idx-1]\n",
    "    what_to_check='test_accuracy'\n",
    "    \n",
    "    acc1 = measure_final_acc(fedavg_1T, what_to_check, global_final_time)\n",
    "    acc2 = measure_final_acc(fedavg_2T, what_to_check, global_final_time)\n",
    "    acc3 = measure_final_acc(fedavg_spc, what_to_check, global_final_time)\n",
    "    acc4 = measure_final_acc(fedavg_wfa, what_to_check, global_final_time)\n",
    "\n",
    "    acc5 = measure_final_acc(fedprox_1T, what_to_check, global_final_time)\n",
    "    acc6 = measure_final_acc(fedprox_2T, what_to_check, global_final_time)\n",
    "    acc7 = measure_final_acc(fedprox_ss, what_to_check, global_final_time)\n",
    "\n",
    "    acc8 = measure_final_acc(fedbalancer, what_to_check, global_final_time)\n",
    "    \n",
    "    if acc1 == max(acc1, acc2, acc3, acc4):\n",
    "        objective = measure_final_acc(fedavg_1T, what_to_check, global_final_time)\n",
    "        tta = measure_time(fedavg_1T, objective, what_to_check)\n",
    "    elif acc2 == max(acc1, acc2, acc3, acc4):\n",
    "        objective = measure_final_acc(fedavg_2T, what_to_check, global_final_time)\n",
    "        tta = measure_time(fedavg_2T, objective, what_to_check)\n",
    "    elif acc3 == max(acc1, acc2, acc3, acc4):\n",
    "        objective = measure_final_acc(fedavg_spc, what_to_check, global_final_time)\n",
    "        tta = measure_time(fedavg_spc, objective, what_to_check)\n",
    "    elif acc4 == max(acc1, acc2, acc3, acc4):\n",
    "        objective = measure_final_acc(fedavg_wfa, what_to_check, global_final_time)\n",
    "        tta = measure_time(fedavg_wfa, objective, what_to_check)\n",
    "    \n",
    "    tta1 = measure_time(fedavg_1T, objective, what_to_check)\n",
    "    tta2 = measure_time(fedavg_2T, objective, what_to_check)\n",
    "    tta3 = measure_time(fedavg_spc, objective, what_to_check)\n",
    "    tta4 = measure_time(fedavg_wfa, objective, what_to_check)\n",
    "\n",
    "    tta5 = measure_time(fedprox_1T, objective, what_to_check)\n",
    "    tta6 = measure_time(fedprox_2T, objective, what_to_check)\n",
    "    tta7 = measure_time(fedprox_ss, objective, what_to_check)\n",
    "\n",
    "    tta8 = measure_time(fedbalancer, objective, what_to_check)\n",
    "    \n",
    "    speedup[batch_idx-1, 0] = tta / tta1\n",
    "    speedup[batch_idx-1, 1] = tta / tta2\n",
    "    speedup[batch_idx-1, 2] = tta / tta3\n",
    "    speedup[batch_idx-1, 3] = tta / tta4\n",
    "    speedup[batch_idx-1, 4] = tta / tta5\n",
    "    speedup[batch_idx-1, 5] = tta / tta6\n",
    "    speedup[batch_idx-1, 6] = tta / tta7\n",
    "    speedup[batch_idx-1, 7] = tta / tta8\n",
    "    \n",
    "    accuracy[batch_idx-1, 0] = acc1\n",
    "    accuracy[batch_idx-1, 1] = acc2\n",
    "    accuracy[batch_idx-1, 2] = acc3\n",
    "    accuracy[batch_idx-1, 3] = acc4\n",
    "    accuracy[batch_idx-1, 4] = acc5\n",
    "    accuracy[batch_idx-1, 5] = acc6\n",
    "    accuracy[batch_idx-1, 6] = acc7\n",
    "    accuracy[batch_idx-1, 7] = acc8\n",
    "\n",
    "print(\"Averaged Results\")\n",
    "print(\"{:15s} | {:11s} | {:10s}\".format('METHOD', 'SPEEDUP', 'ACCURACY'))\n",
    "print(\"{:15s}\".format('FedAvg+1T')+\" | %.2f ± %.2f | %.3f ± %.3f\" % (round(np.mean(speedup[:,0]), 3),round(np.std(speedup[:,0], ddof=1), 3),round(np.mean(accuracy[:,0]), 3),round(np.std(accuracy[:,0], ddof=1), 3)))\n",
    "print(\"{:15s}\".format('FedAvg+2T')+\" | %.2f ± %.2f | %.3f ± %.3f\" % (round(np.mean(speedup[:,1]), 3),round(np.std(speedup[:,1], ddof=1), 3),round(np.mean(accuracy[:,1]), 3),round(np.std(accuracy[:,1], ddof=1), 3)))\n",
    "print(\"{:15s}\".format('FedAvg+SPC')+\" | %.2f ± %.2f | %.3f ± %.3f\" % (round(np.mean(speedup[:,2]), 3),round(np.std(speedup[:,2], ddof=1), 3),round(np.mean(accuracy[:,2]), 3),round(np.std(accuracy[:,2], ddof=1), 3)))\n",
    "print(\"{:15s}\".format('FedAvg+WFA')+\" | %.2f ± %.2f | %.3f ± %.3f\" % (round(np.mean(speedup[:,3]), 3),round(np.std(speedup[:,3], ddof=1), 3),round(np.mean(accuracy[:,3]), 3),round(np.std(accuracy[:,3], ddof=1), 3)))\n",
    "print(\"{:15s}\".format('Prox+1T')+\" | %.2f ± %.2f | %.3f ± %.3f\" % (round(np.mean(speedup[:,4]), 3),round(np.std(speedup[:,4], ddof=1), 3),round(np.mean(accuracy[:,4]), 3),round(np.std(accuracy[:,4], ddof=1), 3)))\n",
    "print(\"{:15s}\".format('Prox+2T')+\" | %.2f ± %.2f | %.3f ± %.3f\" % (round(np.mean(speedup[:,5]), 3),round(np.std(speedup[:,5], ddof=1), 3),round(np.mean(accuracy[:,5]), 3),round(np.std(accuracy[:,5], ddof=1), 3)))\n",
    "print(\"{:15s}\".format('SampleSelection')+\" | %.2f ± %.2f | %.3f ± %.3f\" % (round(np.mean(speedup[:,6]), 3),round(np.std(speedup[:,6], ddof=1), 3),round(np.mean(accuracy[:,6]), 3),round(np.std(accuracy[:,6], ddof=1), 3)))\n",
    "print(\"{:15s}\".format('FedBalancer')+\" | %.2f ± %.2f | %.3f ± %.3f\" % (round(np.mean(speedup[:,7]), 3),round(np.std(speedup[:,7], ddof=1), 3),round(np.mean(accuracy[:,7]), 3),round(np.std(accuracy[:,7], ddof=1), 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
